{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 路径没有加载，需要os导入内存\n",
    "import os\n",
    "os.chdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据，209张（64，46，3）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_1_2.lr_utils import  load_dataset\n",
    "\n",
    "train_set_x_orig , train_set_y , test_set_x_orig , test_set_y , classes=load_dataset()\n",
    "\n",
    "classes=[i.decode() for i in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig=train_set_x_orig/255\n",
    "\n",
    "test_set_x_orig=test_set_x_orig/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据进行flatten\n",
    "train_set_x_orig=train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T\n",
    "test_set_x_orig =test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288, 50)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_x_orig.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型\n",
    "\n",
    "\n",
    "- 初始化模型的参数\n",
    "- 定义模型结构（例如输入特征的数量）\n",
    "- 循环：\n",
    "\n",
    "    - 计算当前损失（正向传播）\n",
    "\n",
    "    - 计算当前梯度（反向传播）\n",
    "\n",
    "    - 更新参数（梯度下降）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先定义一个sigmod函数\n",
    "def sigmod(z):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "        z - shape为（1,209）的模型矩阵\n",
    "    \n",
    "    1是指每一个图片计算完z=w*x+b模型之后的值（w和x不止一个）\n",
    "    np.exe是指对每一个z求e^x，是一个SIMD操作，之后的除法和加法都是遵循广播算法进行的，可以达到\n",
    "    对209张图片进行sigmod函数计算\n",
    "    \n",
    "    返回：\n",
    "        res - shape应为（1,209）的矩阵\n",
    "    \n",
    "    209个样本运算完sigmod的值\n",
    "    \n",
    "    \"\"\"\n",
    "    res=1/(1+np.exp(-z))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "after sigmod:\n",
      " [[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "# 验证若有4个样本\n",
    "a=np.zeros(shape=(4,2))\n",
    "c=copy.copy(a)\n",
    "b=sigmod(c)\n",
    "print(\"original:\\n\",a)\n",
    "print(\"after sigmod:\\n\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化weight和bias\n",
    "def initialize(shape):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "        shape - x数据的形状\n",
    "         \n",
    "    模型的形状，需要创建对应attribute个的weight，attribute的个数其实就是pixel的个数=height*width*channel\n",
    "    bias的初始化只需声明一个实数，因为遵循广播原则，所以会自动补齐\n",
    "    \n",
    "    返回：\n",
    "        w - 带有初始化的权重矩阵\n",
    "        b - 带有初始化的bias矩阵\n",
    "        \n",
    "    对应shape个的weitht和单独的bias\n",
    "    \"\"\"\n",
    "\n",
    "    w=np.zeros(shape=(shape[0],1))\n",
    "    b=0\n",
    "    assert(w.shape==(shape[0],1))\n",
    "    assert(isinstance(b,float)or isinstance(b,int))\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "def build_model(w,b,x,y):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "        w  - 权重，大小不等的数组（num_px * num_px * 3，1）\n",
    "        b  - 偏差，一个标量\n",
    "        X  - 矩阵类型为（num_px * num_px * 3，训练数量）\n",
    "        Y  - 真正的“标签”矢量（如果非猫则为0，如果是猫则为1），矩阵维度为(1,训练数据数量)\n",
    "\n",
    "    返回：\n",
    "        cost- 逻辑回归的负对数似然成本\n",
    "        dw  - 相对于w的损失梯度，因此与w相同的形状\n",
    "        db  - 相对于b的损失梯度，因此与b的形状相同\n",
    "    \n",
    "    实现前向和后向传播的成本函数及其梯度\n",
    "   \"\"\"\n",
    "\n",
    "    # 模型建立\n",
    "    z=np.dot(w.T,x)+b\n",
    "\n",
    "    # m为样本数    \n",
    "    m=x.shape[1]\n",
    "    \n",
    "    # 正向传播\n",
    "    \n",
    "    # 计算sigmod值\n",
    "    a=sigmod(z)\n",
    "\n",
    "    J=(y*np.log(a))+(1-y)*np.log(1-a)\n",
    "    \n",
    "    cost=(-1/m)*J.sum()\n",
    "    \n",
    "    # 反向更新参数\n",
    "\n",
    "    # 因为dw=x*dz 且dz为dj/dz\n",
    "    dz=a-y\n",
    "    \n",
    "    # 通过矩阵乘积可以直接计算相加后的各个attribute的值    \n",
    "    dw=(1/m)*np.dot(x,dz.T)\n",
    "    \n",
    "    db=(1/m)*np.sum(dz)\n",
    "    \n",
    "    \n",
    "    assert(dw.shape==(x.shape[0],1))\n",
    "    assert(db.shape==())\n",
    "    assert(cost.shape==())\n",
    "    grads={\"dw\":dw,\n",
    "              \"db\":db}\n",
    "    \n",
    "    return cost,grads\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行优化\n",
    "- 通过不断的更新参数来降低cost值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize\n",
    "def optimize(w,b,x,y,iterations,lr,print_cost = False):\n",
    "    \"\"\"\n",
    "      参数：\n",
    "        w  - 权重，大小不等的数组（num_px * num_px * 3，1）\n",
    "        b  - 偏差，一个标量\n",
    "        x  - 维度为（height * weight * 3，训练数据的数量）的数组。\n",
    "        y  - 真正的“标签”矢量（如果非猫则为0，如果是猫则为1），矩阵维度为(1,训练数据的数量)\n",
    "        iterations  - 优化循环的迭代次数\n",
    "        lr  - 梯度下降更新规则的学习率\n",
    "        print_cost  - 每100步打印一次损失值\n",
    "    \n",
    "    返回：\n",
    "        params  - 包含权重w和偏差b的字典\n",
    "        grads  - 包含权重和偏差相对于成本函数的梯度的字典\n",
    "        cost - 优化期间计算的所有成本列表，将用于绘制学习曲线。\n",
    "    \"\"\"\n",
    "    costs=[]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        cost,grads=build_model(w,b,x,y)\n",
    "        \n",
    "        w=w-lr*grads[\"dw\"]\n",
    "        b=b-lr*grads[\"db\"]\n",
    "        \n",
    "        # 记录cost\n",
    "        if i%100==0: \n",
    "            costs.append(cost)\n",
    "            \n",
    "            if print_cost:\n",
    "                print(\"%d次迭代：cost：%f\"%(i,cost))\n",
    "\n",
    "        \n",
    "    params  = {\n",
    "                \"w\" : w,\n",
    "                \"b\" : b }\n",
    "    \n",
    "    return params,costs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.1124579 ]\n",
      " [0.23106775]]\n",
      "b = 1.5593049248448891\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "w, b, X, Y = np.array([[1], [2]]), 2, np.array([[1,2], [3,4]]), np.array([[1, 0]])\n",
    "params , costs = optimize(w , b , X , Y , iterations=100 , lr = 0.009 , print_cost = False)\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w,b,x):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "        w - 已经训练好的权重矩阵\n",
    "        b - 已经训练好的偏置量\n",
    "        x - 待预测的x数据\n",
    "        \n",
    "    返回：\n",
    "        y_predict - 各个样本的预测值\n",
    "    \"\"\"\n",
    "    \n",
    "    m=x.shape[1]\n",
    "    \n",
    "    y_predict=np.zeros(shape=(1,m))\n",
    "    \n",
    "    w=w.reshape(x.shape[0],1)\n",
    "    \n",
    "    z=np.dot(w.T,x)+b\n",
    "    \n",
    "    a=sigmod(z)\n",
    "    \n",
    "    for i in range(m):\n",
    "        y_predict[0,i]=1 if a[0,i]>0.5 else 0\n",
    "    \n",
    "    assert(y_predict.shape==(1,m))\n",
    "    return y_predict.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[1 1]]\n"
     ]
    }
   ],
   "source": [
    "w, b, X, Y = np.array([[1], [2]]), 2, np.array([[1,2], [3,4]]), np.array([[1, 0]])\n",
    "print(\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对模型进行封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_x,train_y,test_x,test_y,iterations,lr,print_cost = False):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "        x_train  - 维度为（height * weight * 3，训练数据的数量）训练集的数组。\n",
    "        y_train  - 真正的训练集的“标签”矢量（如果非猫则为0，如果是猫则为1），矩阵维度为(1，训练数据的数量)\n",
    "        x_test  - 维度为（height * weight * 3，训练数据的数量）测试集的数组。\n",
    "        y_test  - 真正的测试集的“标签”矢量（如果非猫则为0，如果是猫则为1），矩阵维度为(1，测试数据的数量)\n",
    "        iterations  - 优化循环的迭代次数\n",
    "        lr  - 梯度下降更新规则的学习率\n",
    "        print_cost  - 每100步打印一次损失值\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # 初始化参数\n",
    "    w,b=initialize(train_x.shape)\n",
    "    # 建立模型并优化\n",
    "    params,costs=optimize(w=w,b=b,x=train_x,y=train_y,iterations=iterations,lr=lr,print_cost = print_cost)\n",
    "    \n",
    "    predict_train_y=predict(params[\"w\"],params[\"b\"],train_x)\n",
    "    \n",
    "    predict_test_y=predict(params[\"w\"],params[\"b\"],test_x)\n",
    "    \n",
    "    acc_train=np.mean(np.equal(predict_train_y,train_y))\n",
    "    acc_test=np.mean(np.equal(predict_test_y,test_y))\n",
    "    \n",
    "    print(\"Acc_train:\"+str(acc_train*100)+\"%\")\n",
    "    print(\"Acc_test:\"+str(acc_test*100)+\"%\")\n",
    "    \n",
    "    return costs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    print(train_set_x_orig.shape)\n",
    "    print(test_set_x_orig.shape)\n",
    "    costs=model(train_x=train_set_x_orig,train_y=train_set_y,test_x=test_set_x_orig,test_y=test_set_y,iterations=2000,lr=0.01,print_cost = True)\n",
    "    return costs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 209)\n",
      "(12288, 50)\n",
      "True\n",
      "0次迭代：cost：0.693147\n",
      "100次迭代：cost：0.823921\n",
      "200次迭代：cost：0.418944\n",
      "300次迭代：cost：0.617350\n",
      "400次迭代：cost：0.522116\n",
      "500次迭代：cost：0.387709\n",
      "600次迭代：cost：0.236254\n",
      "700次迭代：cost：0.154222\n",
      "800次迭代：cost：0.135328\n",
      "900次迭代：cost：0.124971\n",
      "1000次迭代：cost：0.116478\n",
      "1100次迭代：cost：0.109193\n",
      "1200次迭代：cost：0.102804\n",
      "1300次迭代：cost：0.097130\n",
      "1400次迭代：cost：0.092043\n",
      "1500次迭代：cost：0.087453\n",
      "1600次迭代：cost：0.083286\n",
      "1700次迭代：cost：0.079487\n",
      "1800次迭代：cost：0.076007\n",
      "1900次迭代：cost：0.072809\n",
      "Acc_train:99.52153110047847%\n",
      "Acc_test:70.0%\n"
     ]
    }
   ],
   "source": [
    "costs=run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6931471805599453,\n",
       " 0.8239208681629392,\n",
       " 0.4189443741523992,\n",
       " 0.6173497043891899,\n",
       " 0.5221157712553265,\n",
       " 0.3877087484834722,\n",
       " 0.23625445672833312,\n",
       " 0.15422213306441673,\n",
       " 0.13532782831640808,\n",
       " 0.12497148000431883,\n",
       " 0.11647833125791879,\n",
       " 0.10919251128264036,\n",
       " 0.10280446418272579,\n",
       " 0.0971298100799662,\n",
       " 0.09204326923642153,\n",
       " 0.08745251991763427,\n",
       " 0.0832860305362993,\n",
       " 0.07948657037807491,\n",
       " 0.07600734572080525,\n",
       " 0.07280949458514266]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
